{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8696c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm\n",
    "from dateutil.parser import parse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from spacy.matcher import Matcher\n",
    "import datetime\n",
    "import csv\n",
    "import nltk\n",
    "\n",
    "\n",
    "\n",
    "path_Mattia = 'C:/Users/matti/AppData/Roaming/Python/Python38/site-packages/it_nerIta_trf/it_nerIta_trf-0.0.0'\n",
    "               \n",
    "nlp = spacy.load(path_Mattia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92d072bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging ora inizio:  2023-03-20 11:23:05.597636\n"
     ]
    }
   ],
   "source": [
    "def pulizia(path_file , nome):\n",
    "    sentenze = lettura_pulizia(path_file)\n",
    "    for key in sentenze: \n",
    "        sentenze[key]= elimina(sentenze[key])\n",
    "    crea = trascrizione_pulizia(sentenze , nome)\n",
    "    return None\n",
    "\n",
    "def lettura_pulizia(path_file):\n",
    "    df = pd.read_csv(path_file, encoding = 'utf-8', sep=';')\n",
    "    df = df.dropna(subset=['numerosentenza', 'annosentenza', 'parte'])\n",
    "    sentenze = {}\n",
    "    #conta = 1\n",
    "    for index, row in df.iterrows():\n",
    "        #if conta == 10:\n",
    "         #   break\n",
    "        #conta +=1\n",
    "        key = str(int(row['numerosentenza'])) + '_' +str(int(row['annosentenza'])) + '_' +(row['parte'].replace(' ', '_'))\n",
    "        value = row['text'].replace('\\n', ' ')\n",
    "        sentenze[key] = value.split('Content-Type application/pdf')[1]\n",
    "    return sentenze\n",
    "\n",
    "\n",
    "\n",
    "def elimina(testo):\n",
    "    mesi = {' gennaio ': '/01/', ' febbraio ': '/02/',  ' marzo '    : '/03/', ' aprile ' : '/04/', ' maggio '  : '/05/',\n",
    "        ' giugno ': '/06/', ' luglio ' : '/07/', ' agosto '  : '/08/',  ' settembre ': '/09/',\n",
    "        ' ottobre ': '/10/', ' novembre ': '/11/', ' dicembre ': '/12/'}\n",
    "    for i, j in mesi.items():\n",
    "        testo = re.sub(i, j, testo, flags=re.IGNORECASE) \n",
    "    testo = re.sub(r\"\\bpagina\\s*\\d+\\s*(di\\s*\\d+)?|\\bpage\\s*(\\d+)?\\s*(di\\s*\\d+)?\", \"\", testo, flags=re.IGNORECASE)\n",
    "    testo = re.sub(r'(=){2,}|(-){2,}|§|\\*|°|acroform|AUTVEND|','', testo, flags=re.IGNORECASE)\n",
    "    testo = re.sub(r'\\s+', ' ', testo)\n",
    "    testo = re.sub(r'\\s+[0-9]+/(n\\.\\s*)?[0-9]+[\\s,.;\\)]|n\\.\\s*[0-9]+/(n\\.\\s*)?[0-9]+[\\s,.;\\)]|numero\\s*[0-9]+\\s*del\\s*[0-9]+', \" ##Numero/Anno \", testo) ##NUMERO/ANNO\n",
    "    testo = re.sub(r'(C\\.F\\.\\s*)?\\s*[A-Z]{3}\\s*[A-Z]{3}\\s*\\d{2}\\s*[A-Z]\\d{2}\\s*[A-Z]\\d{3}\\s*[A-Z]', \" ##Cod_F \", testo, flags=re.IGNORECASE) #CODICE FISCALE\n",
    "    testo = re.sub(r'(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', \" ##URL \", testo, flags=re.IGNORECASE) #URL\n",
    "    testo = re.sub(r'F\\s*i\\s*r\\s*m\\s*a\\s*t\\s*o\\s*D\\s*a\\s*:\\s*[A-Z]*\\s*[A-Z]*\\s*[A-Z]*\\s*[A-Z]*\\s*[A-Z]*\\s*[A-Z]*\\s*[A-Z]*\\s*[A-Z]*\\s*[A-Z]*\\s*[A-Z]*\\s*[A-Z]*\\s*[A-Z]*\\s*', \" \", testo)\n",
    "    testo = re.sub(r'(E)?\\s*m es so D a\\s*:\\s*([A-Z0-9.]{0,2}\\s+)*', ' ', testo)\n",
    "    testo = re.sub(r'[D\\s+]a:\\s*([A-Z0-9.]{0,2}\\s+)*', ' ', testo)\n",
    "    testo = re.sub(r'\\S\\s*e\\s*r\\s*i\\s*a\\s*l\\s*#\\s*:\\s*([a-z0-9]{0,3}\\s+)*', ' ', testo)\n",
    "    testo = re.sub(r'\\bsignaturedata date \\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\+\\d{4}\\b', '', testo ,flags=re.IGNORECASE)\n",
    "    return testo\n",
    "\n",
    "def trascrizione_pulizia(sentenze, nome):\n",
    "    with open('/home/gueststudente/Giustizia/Pre-processing/Pipeline_files/Cleaning/'+ nome +'_pulizia.csv', \"w\",  encoding = 'utf-8') as output:\n",
    "        writer = csv.writer(output)\n",
    "        for key, value in sentenze.items():\n",
    "            writer.writerow([key, value])\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def divisione(file):    \n",
    "    sentenze = lettura_divisione(file)\n",
    "    chiave_e_capitoli = lettura_chiave_e_capitoli(file)\n",
    "    sentenze_sbagliate = lettura_sentenze_sbagliate(file)\n",
    "    chiave_e_capitoli, sentenze_corrette , sentenze_sbagliate = capitoli(sentenze, chiave_e_capitoli, sentenze_sbagliate)\n",
    "    controllo = check(sentenze_corrette , sentenze_sbagliate)\n",
    "    trascrizione_divisione(chiave_e_capitoli, sentenze_sbagliate, file)\n",
    "    return chiave_e_capitoli , controllo\n",
    "\n",
    "def lettura_divisione(file):\n",
    "    with open('/home/gueststudente/Giustizia/Pre-processing/Pipeline_files/Cleaning/'+ file +'_pulizia.csv', mode='r', encoding = 'utf-8' ) as file:\n",
    "        reader = csv.reader(file , delimiter=',')\n",
    "        sentenze = {} \n",
    "        for row in reader:\n",
    "            if len(row) < 2:\n",
    "                print(len(row))\n",
    "                continue\n",
    "            sentenze[row[0]] = row[1]\n",
    "    return sentenze\n",
    "\n",
    "\n",
    "\n",
    "def chiave(intestazione):\n",
    "    ## manca ancora l'estrattore della città che serve come chiave\n",
    "    intestazione = intestazione.replace(':','SEPARATORE').replace(',','SEPARATORE').split('SEPARATORE')\n",
    "    intestazione = ('_'+intestazione[0]+'_'+intestazione[11]+'_'+intestazione[4]).replace(' ', '')\n",
    "    return intestazione\n",
    "\n",
    "\n",
    "def divisore(sentenza, divisori):\n",
    "    for div in divisori:\n",
    "        sentenza = sentenza.replace(div, 'DIVISORI__' )\n",
    "    last_occurrence_index = sentenza.rfind('DIVISORI__')\n",
    "    if last_occurrence_index != -1:\n",
    "        sentenza = sentenza[:last_occurrence_index] + 'DIVISORE_SEZIONE' + sentenza[last_occurrence_index + len('DIVISORI__'):] \n",
    "    sentenza = sentenza.replace('DIVISORI__', ' ')\n",
    "    return sentenza\n",
    "\n",
    "def lettura_chiave_e_capitoli(file):\n",
    "    with open('/home/gueststudente/Giustizia/Pre-processing/Pipeline_files/Division/'+ file + '_divisione.csv', 'r',  encoding = 'utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        chiave_e_capitoli = list(reader)\n",
    "    return chiave_e_capitoli\n",
    "\n",
    "def lettura_sentenze_sbagliate(file):\n",
    "    with open(\"/home/gueststudente/Giustizia/Pre-processing/Pipeline_files/Division/\" + file + \"_divisioni_sbagliate.txt\", \"r\", encoding = 'utf-8') as file:\n",
    "        sentenze_sbagliate = file.read().splitlines()\n",
    "    return sentenze_sbagliate\n",
    "\n",
    "def capitoli(sentenze, chiave_e_capitoli, sentenze_sbagliate):\n",
    "    sentenze_csv = [col[0] for col in chiave_e_capitoli]\n",
    "    for key in sentenze:\n",
    "        if key in sentenze_csv:\n",
    "            continue\n",
    "        else:\n",
    "            sentenza , errore  =  divisione_capitoli(sentenze[key])\n",
    "            print(len(sentenza))\n",
    "            if errore:\n",
    "                sentenze_sbagliate.append(key)\n",
    "            else:\n",
    "                #print(key) mi serve per vedere cosa recupera in caso quando lavoro sulle divisioni sbagliate\n",
    "                chiave_e_capitoli.append([key, sentenza[0], sentenza[1], sentenza[2]])\n",
    "                if key in sentenze_sbagliate:\n",
    "                    sentenze_sbagliate.remove(key)\n",
    "    sentenze_csv = [col[0] for col in chiave_e_capitoli]\n",
    "    return chiave_e_capitoli, sentenze_csv, sentenze_sbagliate\n",
    "\n",
    "def check(sentenze_corrette , sentenze_sbagliate):\n",
    "    intersection = list(set(sentenze_corrette) & set(sentenze_sbagliate))\n",
    "    if intersection != []:\n",
    "        print ('errore check')\n",
    "        return intersection\n",
    "    return None\n",
    "\n",
    "def trascrizione_divisione(chiave_e_capitoli , sentenze_sbagliate , file):\n",
    "    sentenze_sbagliate = [elemento.replace('\\n', '') for elemento in sentenze_sbagliate]\n",
    "    sentenze_sbagliate = [elemento for elemento in sentenze_sbagliate if elemento != '']\n",
    "    sentenze_sbagliate = set(sentenze_sbagliate)\n",
    "    with open(\"/home/gueststudente/Giustizia/Pre-processing/Pipeline_files/Division/\" + file + \"_divisioni_sbagliate.txt\", \"w\", encoding = 'utf-8') as output:\n",
    "        for item in sentenze_sbagliate:\n",
    "            output.write(\"%s\\n\" % item)\n",
    "    \n",
    "    with open('/home/gueststudente/Giustizia/Pre-processing/Pipeline_files/Division/'+ file + '_divisione.csv' , 'w', newline='',  encoding = 'utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(chiave_e_capitoli)\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def divisione_capitoli(sentenza):\n",
    "    #sentenza = re.sub(\"\\s*MOTIVIDELLADECISIONE\\s*\", \"MOTIVI DELLA DECISIONE\", sentenza, flags=re.IGNORECASE)\n",
    "    #sentenza = re.sub(\"\\s*RAGIONIINFATTOEDIRITTODELLADECISIONE\\s*\", \"RAGIONI IN FATTO E DIRITTO DELLA DECISIONE\", sentenza, flags=re.IGNORECASE)\n",
    "    #sentenza = re.sub(\"\\s*FATTOEDIRITTO\\s*\", \"FATTO E DIRITTO\", sentenza, flags=re.IGNORECASE)\n",
    "\n",
    "    divisori_1 = ['MOTIVI DELLA DECISIONE',\n",
    "                  'RAGIONI IN FATTO E DIRITTO DELLA DECISIONE',\n",
    "                  'FATTO E DIRITTO',\n",
    "                  'RAGIONI IN FATTO ED IN DIRITTO DELLA DECISIONE',\n",
    "                  'MOTIVI IN FATTO E IN DIRITTO',\n",
    "                  'Svolgimento del processo e motivi della decisione',\n",
    "                  'S V O L G I M E N T O D E L P R O C E S S O', \n",
    "                  'RAGIONI DELLA DECISIONE',\n",
    "                  'Motivi della decisione' ,\n",
    "                  'Svolgimento del processo',\n",
    "                  'C O N S I D E R A T O',\n",
    "                  'MOTIVAZIONE',\n",
    "                  'CONCLUSIONI DELLE PARTI',\n",
    "                  'CON LA PARTECIPAZIONE DEL PUBBLICO MINISTERO ',\n",
    "                  'SVOLGIMENTO DEL PROC ESSO', \n",
    "                  'svolgimento del processo',\n",
    "                  'RAGIONI DI FATTO E DI DIRITTO  DELLA  DECISIONE',\n",
    "                  'RAGIONI DI FATTO E DI DIRITTO',\n",
    "                 'MOTIVI DELLA DECISIONE IN FATTO E DIRITTO',\n",
    "                  'CONCLUSIONI',\n",
    "                 'Conclusioni rassegnate congiuntamente dalle parti:',\n",
    "                 'N O N C H E'] #ed affini (attenzione a svolgmento e motivi)\n",
    "    #provare ad aggiungere \"N O N C H E'\" e togliere \"CONCLUSIONI\"  \n",
    "    # 'conclusioni delle parti :' 'CONCLUSIONI' ,'Conclusioni delle parti:'\n",
    "    divisori_2 = [ 'P.Q.M',\n",
    "                  'P. Q. M',\n",
    "                  'P. Q. M',\n",
    "                  'P.   Q.   M',\n",
    "                  'M O T I V I D E L L A D E C I S I O N E',\n",
    "                  'P Q M',\n",
    "                 'p.q.m' ,\n",
    "                  'PQM' , \n",
    "                  'P.Q.M',\n",
    "                  'P.Q.M.',\n",
    "                  'P.Q.M.'] #ed affini  \n",
    "    sentenza = divisore(sentenza, divisori_1)\n",
    "    sentenza = divisore(sentenza, divisori_2)  ###QUI DEVO CONTARE QUANTE VOLTE AVVIENE IL REPLACEMENT e segnarlo in \n",
    "                                                ### in qualche modo\n",
    "    sentenza = sentenza.split('DIVISORE_SEZIONE')\n",
    "    if len(sentenza) != 3: ##per ora il numero  atteso è 3, poi si vedrà\n",
    "        return sentenza , True\n",
    "    else:\n",
    "        return sentenza , False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def anonimizzazione(file, capitolo):\n",
    "    frasi = lettura_anonimizzazione(file, capitolo)\n",
    "    testo = anonimizzazione_frasi(frasi)\n",
    "    testo =accorpa(testo)\n",
    "    trascrizione_anonimizzazione(testo, file, capitolo) \n",
    "    return testo\n",
    "\n",
    "def lettura_anonimizzazione(file, capitolo):\n",
    "    var_lettura = lettura_chiave_e_capitoli(file)\n",
    "    frasi = []\n",
    "    for sentenza in var_lettura:\n",
    "        sentenza = sentenza[int(capitolo)]\n",
    "        #sentenza = sentenza.replace(',', ' ,').replace('.', ' .').replace(':', ' :').replace(';', ' ;').replace( '(', '( ').replace(')', ' )')\n",
    "        frasi.append(sentenza)\n",
    "    return frasi    \n",
    "\n",
    "def anonimizzazione_frasi(lista):\n",
    "    testo = ''\n",
    "    for text in lista:\n",
    "        print('indice: ', lista.index(text))\n",
    "        doc = nlp(text) #########\n",
    "        new = text\n",
    "        for e in reversed(doc.ents):\n",
    "            start = e.start_char\n",
    "            end = start + len(e.text)\n",
    "            text = text[:start] + e.label_ + text[end:]\n",
    "        testo +=  text\n",
    "        testo += '\\n' ## '\\n\\n'\n",
    "    return testo#.replace(' .', '.').replace(' ;', ';').replace(' :', ':').replace(' ,', ',').replace( '( ', '(').replace(' )', ')')\n",
    "\n",
    "def accorpa(testo):\n",
    "    etichette = [\"PER\", \"NORP\", \"ORG\", \"GPE\", \"LOC\", \"DATE\", \"MONEY\", \"FAC\", \"PRODUCT\", \"EVENT\",\n",
    "                     \"LAW\", \"TIME\", \"PERCENT\", \"QUANTITY\", \"ORDINAL\", \"CARDINAL\", \"WORK_OF_ART\", \"LANGUAGE\"]\n",
    "    for etichetta in etichette:\n",
    "        etichetta = etichetta\n",
    "        testo = re.sub(r'('+etichetta+ '\\s*){2,}', etichetta + ' ' , testo)\n",
    "    return(testo)\n",
    "\n",
    "def trascrizione_anonimizzazione(testo ,file, capitolo):\n",
    "    with open(\"/home/gueststudente/Giustizia/Pre-processing/Pipeline_files/De-istantiation/\" + file + \"_\"  + capitolo + \".txt\", \"w\",  encoding = 'utf-8') as output:  \n",
    "        output.write(\"%s\\n\" % testo)\n",
    "    output.close()\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_dataframe(text_files, capitolo,  length = '99999'):\n",
    "    phrases = []\n",
    "    conta = 0\n",
    "    for i, text_file in enumerate(text_files):\n",
    "        with open(text_file, encoding = 'utf-8') as file:\n",
    "            content = file.read()\n",
    "            phrases.extend(content.split('\\n')) #se non va '\\n\\n\\n\\n'\n",
    "    phrases = max_lunghezza(phrases, length)\n",
    "    df = pd.DataFrame({'Capitoli': phrases}, index=range(len(phrases)))\n",
    "    df['Capitoli'] = df['Capitoli'].str.replace('\\n', '')    \n",
    "    df.to_csv('/home/gueststudente/Giustizia/Pre-processing/Pipeline_files/Merging/merge_' + capitolo + '_'+ length + '.csv', index=False, encoding = 'utf-8' )\n",
    "    return df\n",
    "\n",
    "def max_lunghezza(phrases, length = '99999'):\n",
    "    lista_finale = []\n",
    "    for capitolo in phrases:\n",
    "        doc = nlp2(capitolo)\n",
    "        for sent in doc.sents:\n",
    "            if sent.text.split() > 10:\n",
    "                lista_finale.append(sent.text)\n",
    "            \n",
    "    return lista_finale\n",
    "\n",
    "\n",
    "nlp2 = spacy.load(\"it_core_news_lg\")\n",
    "start_time = datetime.datetime.now()\n",
    "print('Merging ora inizio: ', start_time )\n",
    "\n",
    "\n",
    "if False:\n",
    "    start_time = datetime.datetime.now()\n",
    "    print('Divisione ora inizio: ', start_time )\n",
    "    division = divisione(\"0\")\n",
    "    division = divisione(\"1\")\n",
    "    division = divisione(\"2\")\n",
    "    division = divisione(\"3\")\n",
    "    division = divisione(\"4\")\n",
    "    end_time = datetime.datetime.now()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(\"Divisione tempo trascorso:\", elapsed_time)\n",
    "\n",
    "\n",
    "    start_time = datetime.datetime.now()\n",
    "    print('Pulizia ora inizio: ', start_time )\n",
    "    clean = pulizia('/home/gueststudente/Giustizia/Pre-processing/Original_sentences/GLSA/0.csv', \"0\")\n",
    "    clean = pulizia('/home/gueststudente/Giustizia/Pre-processing/Original_sentences/GLSA/1.csv', \"1\")\n",
    "    clean = pulizia('/home/gueststudente/Giustizia/Pre-processing/Original_sentences/GLSA/2.csv', \"2\")\n",
    "    clean = pulizia('/home/gueststudente/Giustizia/Pre-processing/Original_sentences/GLSA/3.csv', \"3\")\n",
    "    clean = pulizia('/home/gueststudente/Giustizia/Pre-processing/Original_sentences/GLSA/4.csv', \"4\")\n",
    "    end_time = datetime.datetime.now()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(\"Pulizia Tempo trascorso:\", elapsed_time)\n",
    "\n",
    "    start_time = datetime.datetime.now()\n",
    "    print('Anonimizzazione ora inizio: ', start_time )\n",
    "    anonymizationa = anonimizzazione(\"0\", '2')\n",
    "    anonymizationa = anonimizzazione(\"1\", '2')\n",
    "    anonymizationa = anonimizzazione(\"2\", '2')\n",
    "    anonymizationa = anonimizzazione(\"3\", '2')\n",
    "    anonymizationa = anonimizzazione(\"4\", '2')\n",
    "    end_time = datetime.datetime.now()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(\"Anonimizzazione tempo trascorso:\", elapsed_time)\n",
    "    \n",
    "    files = ['/home/gueststudente/Giustizia/Pre-processing/Pipeline_files/De-istantiation/0_2.txt',\n",
    "        '/home/gueststudente/Giustizia/Pre-processing/Pipeline_files/De-istantiation/1_2.txt',\n",
    "        '/home/gueststudente/Giustizia/Pre-processing/Pipeline_files/De-istantiation/2_2.txt',\n",
    "        '/home/gueststudente/Giustizia/Pre-processing/Pipeline_files/De-istantiation/3_2.txt',\n",
    "        '/home/gueststudente/Giustizia/Pre-processing/Pipeline_files/De-istantiation/4_2.txt',\n",
    "    ]\n",
    "    merging = create_dataframe(files, '2')\n",
    "    end_time = datetime.datetime.now()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(\"Merging tempo trascorso:\", elapsed_time)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24213d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(text_files, capitolo,  length = '99999'):\n",
    "    phrases = []\n",
    "    conta = 0\n",
    "    for i, text_file in enumerate(text_files):\n",
    "        with open(text_file, encoding = 'utf-8') as file:\n",
    "            content = file.read()\n",
    "            phrases.extend(content.split('\\n')) #se non va '\\n\\n\\n\\n'\n",
    "    phrases = max_lunghezza(phrases, length)\n",
    "    df = pd.DataFrame({'Capitoli': phrases}, index=range(len(phrases)))\n",
    "    df['Capitoli'] = df['Capitoli'].str.replace('\\n', '')    \n",
    "    df.to_csv('/home/gueststudente/Giustizia/Pre-processing/Pipeline_files/Merging/merge_' + capitolo + '_'+ length + '.csv', index=False, encoding = 'utf-8' )\n",
    "    return df\n",
    "\n",
    "def max_lunghezza(phrases, length = '99999'):\n",
    "    lista_finale = []\n",
    "    for capitolo in phrases:\n",
    "        doc = nlp2(capitolo)\n",
    "        for sent in doc.sents:\n",
    "            if sent.text.split() > 10:\n",
    "                lista_finale.append(sent.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
